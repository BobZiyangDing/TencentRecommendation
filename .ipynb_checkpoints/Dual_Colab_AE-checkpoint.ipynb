{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-Collaborative Filtering Autoencoder Distance Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "def sparseEmbed(df, name, num, colIdx):\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)] \n",
    "    Emptydf = pd.DataFrame()\n",
    "    Emptydf[embedName] = df[name].str.split('|',expand=True)\n",
    "    values = np.unique(Emptydf[embedName].values)\n",
    "    \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in values:\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "    \n",
    "    \n",
    "    appendValue = np.zeros([Emptydf.values.shape[0], len(values)])\n",
    "    for i in range(Emptydf.values.shape[0]):\n",
    "        for j in range(num):\n",
    "            key = Emptydf.values[i][j]\n",
    "            if key in dic:\n",
    "                appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df\n",
    "\n",
    "def toDummy(df, name, colIdx):\n",
    "    num = len(np.unique(df[name].values.astype(str)))-1\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)]  # don't need nan value\n",
    "        \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in range(num+1):\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "        \n",
    "    appendValue = np.zeros([df[name].size, a])\n",
    "    for i in range(df[name].size):\n",
    "        key = df[name].values[i]\n",
    "        if key in dic:\n",
    "            appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df\n",
    "\n",
    "def genderDummy(df, name, colIdx):\n",
    "    pool = set()\n",
    "    num = len(np.unique(df[name].values))-1\n",
    "    for i in df[name].values:\n",
    "        pool.add(str(i))\n",
    "    num = len(list(pool))-1\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)]  # don't need nan value\n",
    "        \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in range(num+1):\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "        \n",
    "    appendValue = np.zeros([df[name].size, a])\n",
    "    for i in range(df[name].size):\n",
    "        key = df[name].values[i]\n",
    "        if key in dic:\n",
    "            appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data and transforming to categorical binary input data form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with user_7_hero\n",
      "finished with user_30_hero\n",
      "finished with user_7_keyword\n",
      "finished with user_7_author\n",
      "finished with item_author\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_gender_0</th>\n",
       "      <th>user_gender_1</th>\n",
       "      <th>user_gender_2</th>\n",
       "      <th>user_gender_3</th>\n",
       "      <th>user_7_hero_0</th>\n",
       "      <th>user_7_hero_1</th>\n",
       "      <th>user_7_hero_2</th>\n",
       "      <th>user_7_hero_3</th>\n",
       "      <th>user_7_hero_4</th>\n",
       "      <th>...</th>\n",
       "      <th>item_author_519</th>\n",
       "      <th>item_author_520</th>\n",
       "      <th>item_author_521</th>\n",
       "      <th>item_author_522</th>\n",
       "      <th>item_author_523</th>\n",
       "      <th>item_author_524</th>\n",
       "      <th>item_avgTime</th>\n",
       "      <th>item_numReader</th>\n",
       "      <th>item_numTime</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42701</th>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049584</td>\n",
       "      <td>0.633116</td>\n",
       "      <td>0.218448</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138245</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039496</td>\n",
       "      <td>0.111010</td>\n",
       "      <td>0.030510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349992</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164526</td>\n",
       "      <td>0.069714</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399367</th>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_age  user_gender_0  user_gender_1  user_gender_2  user_gender_3  \\\n",
       "42701   0.253333            0.0            1.0            0.0            0.0   \n",
       "138245  0.266667            0.0            1.0            0.0            0.0   \n",
       "349992  0.000000            0.0            0.0            0.0            0.0   \n",
       "42819   0.213333            0.0            1.0            0.0            0.0   \n",
       "399367  0.253333            0.0            1.0            0.0            0.0   \n",
       "\n",
       "        user_7_hero_0  user_7_hero_1  user_7_hero_2  user_7_hero_3  \\\n",
       "42701             0.0            0.0            0.0            0.0   \n",
       "138245            0.0            0.0            0.0            0.0   \n",
       "349992            0.0            0.0            0.0            0.0   \n",
       "42819             0.0            0.0            0.0            0.0   \n",
       "399367            0.0            0.0            0.0            0.0   \n",
       "\n",
       "        user_7_hero_4  ...  item_author_519  item_author_520  item_author_521  \\\n",
       "42701             0.0  ...              0.0              0.0              0.0   \n",
       "138245            0.0  ...              0.0              0.0              0.0   \n",
       "349992            0.0  ...              0.0              0.0              0.0   \n",
       "42819             0.0  ...              0.0              0.0              0.0   \n",
       "399367            0.0  ...              0.0              0.0              0.0   \n",
       "\n",
       "        item_author_522  item_author_523  item_author_524  item_avgTime  \\\n",
       "42701               0.0              0.0              0.0      0.049584   \n",
       "138245              0.0              0.0              0.0      0.039496   \n",
       "349992              0.0              0.0              0.0      0.164526   \n",
       "42819               0.0              0.0              0.0      0.089253   \n",
       "399367              0.0              0.0              0.0      0.000000   \n",
       "\n",
       "        item_numReader  item_numTime  label  \n",
       "42701         0.633116      0.218448    1.0  \n",
       "138245        0.111010      0.030510    0.0  \n",
       "349992        0.069714      0.079814    1.0  \n",
       "42819         0.013798      0.008570    0.0  \n",
       "399367        0.000000      0.000000    0.0  \n",
       "\n",
       "[5 rows x 2119 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = [\"user_age\", \"user_gender\", \"user_7_hero\", \"user_30_hero\", \"user_7_keyword\", \"user_7_author\", \"item_rate\", \"item_keyword\", \"item_author\", \"item_avgTime\", \"item_numReader\", \"item_numTime\", \"label\"]\n",
    "raw = pd.read_csv(\"./thing.txt\", names=head, sep=\",\", index_col = False)\n",
    "\n",
    "colIdx = raw.columns.values.tolist().index(\"user_gender\")\n",
    "raw = genderDummy(raw, \"user_gender\", colIdx)\n",
    "colIdx = raw.columns.values.tolist().index(\"item_keyword\")\n",
    "raw = toDummy(raw, \"item_keyword\", colIdx)\n",
    "\n",
    "numDic = {\"user_gender\": 1, \"user_7_hero\": 5, \"user_30_hero\": 5, \"user_7_keyword\": 3, \"user_7_author\": 3, \"item_keyword\": 1, \"item_author\": 3}\n",
    "for i in [\"user_7_hero\", \"user_30_hero\", \"user_7_keyword\", \"user_7_author\", \"item_author\"]:\n",
    "    colIdx = raw.columns.values.tolist().index(i)\n",
    "    raw = sparseEmbed(raw, i, numDic[i], colIdx)\n",
    "    print(\"finished with\", i)\n",
    "\n",
    "# normalize numerical features into interval [0, 1]\n",
    "for i in [\"user_age\", \"item_rate\", \"item_avgTime\", \"item_numReader\", \"item_numTime\"]:\n",
    "    r = raw[i].values.astype(float)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "    raw_normalized = pd.DataFrame(x_scaled)\n",
    "    raw[i] = raw_normalized\n",
    "\n",
    "raw = raw.sample(200000)\n",
    "    \n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: (3000, 2118) | validate data size: (1000, 2118) | testing data size: (1000, 2118)\n",
      "Epoch:   1 | Train Loss:  +147.69 | Val Loss: +147.684 | Train Neck:   +1.00159764 | Val Neck:   +0.993 | Train AUC:   +0.487 | Val AUC:   +0.515 | TF Break: 01.414 | mean pos dist: 00.500 | mean neg dist 02.410 \n",
      "Epoch:  51 | Train Loss:  +145.80 | Val Loss: +145.743 | Train Neck:   +0.99432635 | Val Neck:   +0.998 | Train AUC:   +0.508 | Val AUC:   +0.506 | TF Break: 01.414 | mean pos dist: 00.500 | mean neg dist 02.410 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'po_vals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-ed3d01807d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_codes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpo_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red: pos dis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m                 \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mneg_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue: neg dis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'po_vals' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = raw.sample(5000)\n",
    "\n",
    "# Splitting dataframe into train, validation, and testing\n",
    "dataY = data['label'].values\n",
    "dataX = data.drop(columns = 'label').values\n",
    "\n",
    "\n",
    "X, Xtest, Y, Ytest = train_test_split(dataX, dataY, test_size = 0.2, random_state = 42)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print(\"training data size: {} | validate data size: {} | testing data size: {}\".format(str(Xtrain.shape), str(Xval.shape), str(Xtest.shape)))\n",
    "\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.05\n",
    "batch_size = 2048\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "num_input = Xtrain.shape[1]\n",
    "num_input_p = data.columns.values.tolist().index(\"item_rate\") # number of all user input columns, the last column ends before the start of \"item_rate\" column\n",
    "num_input_g = data.columns.values.shape[0] - num_input_p - 1   # number of all item input columns, = all column -user -label\n",
    "\n",
    "a = 0.5\n",
    "num_encode_1 = int(256 *a)\n",
    "num_encode_2 = int(124 *a)\n",
    "num_encode_3 = int(64 *a)\n",
    "num_encode_4 = int(32 *a)\n",
    "num_encode_5 = int(16*a)\n",
    "num_encode_6 = int(16*a)\n",
    "\n",
    "num_neck = 8\n",
    "\n",
    "num_decode_1 = num_encode_3\n",
    "num_decode_2 = num_encode_2\n",
    "num_decode_3 = num_encode_1\n",
    "\n",
    "num_output_to_p = num_input_p\n",
    "num_output_to_g = num_input_g\n",
    "\n",
    "#del raw\n",
    "\n",
    "\n",
    "# balance weight coefficient [0,1], the bigger the mode focused onto neck distance\n",
    "alpha = 0.3\n",
    "\n",
    "# regularization\n",
    "beta = 0.0005\n",
    "\n",
    "# collaborative autoencoder input tensor1\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "label = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "weights = {\n",
    "    'encoder_ph1': tf.Variable(tf.random_normal([num_input_p , num_encode_1])),\n",
    "    'encoder_gh1': tf.Variable(tf.random_normal([num_input_g , num_encode_1])),\n",
    "    'encoder_ph2': tf.Variable(tf.random_normal([num_encode_1 , num_encode_2])),\n",
    "    'encoder_gh2': tf.Variable(tf.random_normal([num_encode_1 , num_encode_2])),\n",
    "    'encoder_ph3': tf.Variable(tf.random_normal([num_encode_2 , num_encode_3])),\n",
    "    'encoder_gh3': tf.Variable(tf.random_normal([num_encode_2 , num_encode_3])),    \n",
    "    'encoder_ph4': tf.Variable(tf.random_normal([num_encode_3 , num_encode_4])),\n",
    "    'encoder_gh4': tf.Variable(tf.random_normal([num_encode_3 , num_encode_4])),    \n",
    "    'encoder_ph5': tf.Variable(tf.random_normal([num_encode_4 , num_encode_5])),\n",
    "    'encoder_gh5': tf.Variable(tf.random_normal([num_encode_4 , num_encode_5])),    \n",
    "    'encoder_ph6': tf.Variable(tf.random_normal([num_encode_5 , num_encode_6])),\n",
    "    'encoder_gh6': tf.Variable(tf.random_normal([num_encode_5 , num_encode_6])),        \n",
    "    \n",
    "    'encoder_pneck': tf.Variable(tf.random_normal([num_encode_6 , num_neck])), ## METRIC SPACE OF PERSON\n",
    "    'encoder_gneck': tf.Variable(tf.random_normal([num_encode_6 , num_neck])), ## METRIC SPACE OF GOODS\n",
    "    \n",
    "    'decoder_gh1': tf.Variable(tf.random_normal([num_neck , num_decode_1])),\n",
    "    'decoder_ph1': tf.Variable(tf.random_normal([num_neck , num_decode_1])),\n",
    "    'decoder_gh2': tf.Variable(tf.random_normal([num_decode_1 , num_decode_2])),\n",
    "    'decoder_ph2': tf.Variable(tf.random_normal([num_decode_1 , num_decode_2])),\n",
    "    \n",
    "    \n",
    "    'decoder_gh3': tf.Variable(tf.random_normal([num_decode_2 , num_decode_3])),\n",
    "    'decoder_ph3': tf.Variable(tf.random_normal([num_decode_2 , num_decode_3])),    \n",
    "    \n",
    "    \n",
    "    'decoder_g_to_p_out': tf.Variable(tf.random_normal([num_decode_3 , num_output_to_p])),\n",
    "    'decoder_p_to_g_out': tf.Variable(tf.random_normal([num_decode_3 , num_output_to_g]))\n",
    "}\n",
    "\n",
    "biases = {  \n",
    "    'encoder_bph1': tf.Variable(tf.random_normal([num_encode_1])),\n",
    "    'encoder_bgh1': tf.Variable(tf.random_normal([num_encode_1])),\n",
    "    'encoder_bph2': tf.Variable(tf.random_normal([num_encode_2])),\n",
    "    'encoder_bgh2': tf.Variable(tf.random_normal([num_encode_2])),\n",
    "    'encoder_bph3': tf.Variable(tf.random_normal([num_encode_3])),\n",
    "    'encoder_bgh3': tf.Variable(tf.random_normal([num_encode_3])),\n",
    "    'encoder_bph4': tf.Variable(tf.random_normal([num_encode_4])),\n",
    "    'encoder_bgh4': tf.Variable(tf.random_normal([num_encode_4])),    \n",
    "    'encoder_bph5': tf.Variable(tf.random_normal([num_encode_5])),\n",
    "    'encoder_bgh5': tf.Variable(tf.random_normal([num_encode_5])),   \n",
    "    'encoder_bph6': tf.Variable(tf.random_normal([num_encode_6])),\n",
    "    'encoder_bgh6': tf.Variable(tf.random_normal([num_encode_6])),       \n",
    "    \n",
    "    'encoder_bpneck': tf.Variable(tf.random_normal([num_neck])), ## METRIC SPACE OF PERSON\n",
    "    'encoder_bgneck': tf.Variable(tf.random_normal([num_neck])), ## METRIC SPACE OF GOODS\n",
    "    'decoder_bgh1': tf.Variable(tf.random_normal([num_decode_1])),\n",
    "    'decoder_bph1': tf.Variable(tf.random_normal([num_decode_1])),\n",
    "    'decoder_bgh2': tf.Variable(tf.random_normal([num_decode_2])),\n",
    "    'decoder_bph2': tf.Variable(tf.random_normal([num_decode_2])),\n",
    "    \n",
    "    \n",
    "    'decoder_bgh3': tf.Variable(tf.random_normal([num_decode_3])),\n",
    "    'decoder_bph3': tf.Variable(tf.random_normal([num_decode_3])),    \n",
    "    \n",
    "    \n",
    "    'decoder_b_g_to_p_out': tf.Variable(tf.random_normal([num_output_to_p])),\n",
    "    'decoder_b_p_to_g_out': tf.Variable(tf.random_normal([num_output_to_g]))\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "\n",
    "    ## Person encoder:\n",
    "    layer_p_1 = tf.nn.relu(tf.add(tf.matmul(x[:, :1376], weights['encoder_ph1']), biases['encoder_bph1']))  ## HARD CODING: 1375 is the ending index of person feature; 1376 the starting index of goods feature\n",
    "    layer_p_2 = tf.nn.relu(tf.add(tf.matmul(layer_p_1, weights['encoder_ph2']), biases['encoder_bph2']))\n",
    "    layer_p_3 = tf.nn.relu(tf.add(tf.matmul(layer_p_2, weights['encoder_ph3']), biases['encoder_bph3']))\n",
    "    layer_p_4 = tf.nn.relu(tf.add(tf.matmul(layer_p_3, weights['encoder_ph4']), biases['encoder_bph4']))\n",
    "    layer_p_5 = tf.nn.relu(tf.add(tf.matmul(layer_p_4, weights['encoder_ph5']), biases['encoder_bph5']))\n",
    "    layer_p_6 = tf.nn.relu(tf.add(tf.matmul(layer_p_5, weights['encoder_ph6']), biases['encoder_bph6']))\n",
    "    \n",
    "    layer_p_neck = tf.nn.sigmoid(tf.add(tf.matmul(layer_p_6, weights['encoder_pneck']), biases['encoder_bpneck']))\n",
    "    \n",
    "    ## Good encoder\n",
    "    layer_g_1 = tf.nn.relu(tf.add(tf.matmul(x[:, 1376:], weights['encoder_gh1']), biases['encoder_bgh1']))  ## HARD CODING: 1375 is the ending index of person feature; 1376 the starting index of goods feature\n",
    "    layer_g_2 = tf.nn.relu(tf.add(tf.matmul(layer_g_1, weights['encoder_gh2']), biases['encoder_bgh2']))\n",
    "    layer_g_3 = tf.nn.relu(tf.add(tf.matmul(layer_g_2, weights['encoder_gh3']), biases['encoder_bgh3']))   \n",
    "    layer_g_4 = tf.nn.relu(tf.add(tf.matmul(layer_g_3, weights['encoder_gh4']), biases['encoder_bgh4']))   \n",
    "    layer_g_5 = tf.nn.relu(tf.add(tf.matmul(layer_g_4, weights['encoder_gh5']), biases['encoder_bgh5']))   \n",
    "    layer_g_6 = tf.nn.relu(tf.add(tf.matmul(layer_g_5, weights['encoder_gh6']), biases['encoder_bgh6']))\n",
    "    \n",
    "    layer_g_neck = tf.nn.sigmoid(tf.add(tf.matmul(layer_g_6, weights['encoder_gneck']), biases['encoder_bgneck']))\n",
    "    \n",
    "    \n",
    "    return layer_p_neck, layer_g_neck\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(p_neck, g_neck):\n",
    "    \n",
    "    ## Good to Person decoder\n",
    "    layer_g_1 = tf.nn.relu(tf.add(tf.matmul(g_neck, weights['decoder_gh1']), biases['decoder_bgh1']))\n",
    "    layer_g_2 = tf.nn.relu(tf.add(tf.matmul(layer_g_1, weights['decoder_gh2']), biases['decoder_bgh2']))\n",
    "    layer_g_3 = tf.nn.relu(tf.add(tf.matmul(layer_g_2, weights['decoder_gh3']), biases['decoder_bgh3']))\n",
    "\n",
    "    layer_g_to_p_out = tf.nn.sigmoid(tf.add(tf.matmul(layer_g_3, weights['decoder_g_to_p_out']), biases['decoder_b_g_to_p_out']))\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Person to Good decoder\n",
    "    layer_p_1 = tf.nn.relu(tf.add(tf.matmul(p_neck, weights['decoder_ph1']), biases['decoder_bph1']))\n",
    "    layer_p_2 = tf.nn.relu(tf.add(tf.matmul(layer_p_1, weights['decoder_ph2']), biases['decoder_bph2']))\n",
    "    layer_p_3 = tf.nn.relu(tf.add(tf.matmul(layer_p_2, weights['decoder_ph3']), biases['decoder_bph3']))\n",
    "\n",
    "    layer_p_to_g_out = tf.nn.sigmoid(tf.add(tf.matmul(layer_p_3, weights['decoder_p_to_g_out']), biases['decoder_b_p_to_g_out']))\n",
    "    \n",
    "    result = tf.concat([layer_g_to_p_out, layer_p_to_g_out], axis = 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def getl2loss(dic):\n",
    "    l2 = 0\n",
    "    for i in dic.keys():\n",
    "        l2 += tf.nn.l2_loss(dic[i])\n",
    "    return l2\n",
    "\n",
    "# Construct model\n",
    "\n",
    "encoder_p, encoder_g = encoder(X)\n",
    "decoder_out = decoder(encoder_p, encoder_g)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_out\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "\n",
    "# Click or not click?\n",
    "neck_distance = tf.reshape(tf.norm(encoder_p-encoder_g, axis = 1), [-1,1])\n",
    "signed_distance = tf.multiply(neck_distance, 2*label-1)\n",
    "negative_mask = tf.less_equal(signed_distance, 0) # Getting a boolean vector that have TRUE for negative entries\n",
    "positive_mask = tf.greater(signed_distance, 0)\n",
    "\n",
    "training = tf.Variable(False)\n",
    "pos_neg_break = tf.Variable(0)\n",
    "\n",
    "if training:\n",
    "    furthest_positive = tf.reduce_mean(tf.boolean_mask(signed_distance, positive_mask))\n",
    "    closest_negative = -tf.reduce_mean(tf.boolean_mask(signed_distance, negative_mask))\n",
    "    \n",
    "    threshold = (furthest_positive + closest_negative) / 2\n",
    "else:\n",
    "    # TESTING: Plug-in pre-determined connec\n",
    "    threshold = pos_neg_break\n",
    "\n",
    "#threshold = pos_neg_break\n",
    "    \n",
    "# Calculating AUC\n",
    "neck_pred = tf.less_equal(neck_distance, threshold) # neck distance based prediction on clicking\n",
    "\n",
    "\n",
    "# collect regularization\n",
    "############## regularizer = tf.nn.\n",
    "\n",
    "\n",
    "# 4 different losses\n",
    "\n",
    "\n",
    "\n",
    "neck_distance = tf.reshape(tf.norm(encoder_p - encoder_g, axis=1), [-1,1])\n",
    "signed_centered_distance = -(neck_distance - tf.reduce_mean(neck_distance))\n",
    "    \n",
    "loss_neck_distance = tf.losses.hinge_loss(label, signed_centered_distance)\n",
    "loss_pred_distance = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "loss_weights = tf.reduce_sum(getl2loss(weights))\n",
    "loss_bias = tf.reduce_sum(getl2loss(biases))\n",
    "\n",
    "loss = alpha * loss_neck_distance + (1-alpha) * loss_pred_distance + beta * (loss_weights + loss_bias)\n",
    "\n",
    "# Define Optimizer\n",
    "p_var_list = [weights[\"encoder_ph1\"], weights[\"encoder_ph2\"], weights[\"encoder_ph3\"], weights[\"encoder_ph4\"], weights[\"encoder_ph5\"], weights[\"encoder_ph6\"], weights[\"encoder_pneck\"], \n",
    "              weights[\"decoder_ph1\"], weights[\"decoder_ph2\"], weights[\"decoder_ph3\"], weights[\"decoder_p_to_g_out\"],\n",
    "              biases[\"encoder_bph1\"], biases[\"encoder_bph2\"], biases[\"encoder_bph3\"], biases[\"encoder_bph4\"], biases[\"encoder_bph5\"], biases[\"encoder_bph6\"], biases[\"encoder_bpneck\"], \n",
    "              biases[\"decoder_bph1\"], biases[\"decoder_bph2\"], biases[\"decoder_bph3\"], biases[\"decoder_b_p_to_g_out\"]]\n",
    "\n",
    "g_var_list = [weights[\"encoder_gh1\"], weights[\"encoder_gh2\"], weights[\"encoder_gh3\"], weights[\"encoder_gh4\"], weights[\"encoder_gh5\"], weights[\"encoder_gh6\"], weights[\"encoder_gneck\"], \n",
    "              weights[\"decoder_gh1\"], weights[\"decoder_gh2\"], weights[\"decoder_gh3\"], weights[\"decoder_g_to_p_out\"],\n",
    "              biases[\"encoder_bgh1\"], biases[\"encoder_bgh2\"], biases[\"encoder_bgh3\"], biases[\"encoder_bgh4\"], biases[\"encoder_bgh5\"], biases[\"encoder_bgh6\"], biases[\"encoder_bgneck\"], \n",
    "              biases[\"decoder_bgh1\"], biases[\"decoder_bgh2\"], biases[\"decoder_bgh3\"], biases[\"decoder_b_g_to_p_out\"]]\n",
    "\n",
    "optimizer_p = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, var_list = p_var_list)\n",
    "optimizer_g = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, var_list = g_var_list)\n",
    "\n",
    "\n",
    "\"\"\"gvs_p = optimizer_p.compute_gradients(loss, var_list = p_var_list)\n",
    "capped_gvs_p = [(tf.clip_by_value(grad, -10., 10.), var) for grad, var in gvs_p]\n",
    "train_op_p = optimizer_p.apply_gradients(capped_gvs)\n",
    "\n",
    "gvs_g = optimizer_g.compute_gradients(loss, var_list = g_var_list)\n",
    "capped_gvs_g = [(tf.clip_by_value(grad, -10., 10.), var) for grad, var in gvs_g]\n",
    "train_op_g = optimizer_g.apply_gradients(capped_gvs)\"\"\"\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "\n",
    "\n",
    "# Start Training\n",
    "# Start a new TF session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    sess.run(local_init)\n",
    "    \n",
    "    \n",
    "    num_train_batches = int(Xtrain.shape[0] / batch_size)\n",
    "    Xtrain = np.array_split(Xtrain, num_train_batches)\n",
    "    Ytrain = np.array_split(Ytrain, num_train_batches)\n",
    "    \n",
    "    for i in range(len(Ytrain)):\n",
    "        Ytrain[i] = np.reshape(Ytrain[i], [-1,1])\n",
    "    Yval = np.reshape(Yval, [-1,1])\n",
    "\n",
    "\n",
    "    # Training with validating\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_train_cost = 0\n",
    "        avg_train_neck_cost = 0\n",
    "        avg_auc = 0\n",
    "        for batch in range(len(Xtrain)):\n",
    "\n",
    "            # optimize the person side\n",
    "            _, l, neck, true_false_break, max_pos_dist, min_neg_dist, pred_train, neck_dis = sess.run([optimizer_p, loss, loss_neck_distance, threshold, furthest_positive, closest_negative, neck_pred, neck_distance],  \n",
    "                                                        #{optimizer:_, loss:l, loss_neck_distance:neck, threshold:true_false_break, furthest_positive:max_pos_dist, closest_negative:min_neg_dist, neck_pred:pred_train, neck_distance = neck_dis}\n",
    "                                                        feed_dict={X: Xtrain[batch], label: Ytrain[batch], training: True, pos_neg_break: 0}) # because it is training, it doesn't matter what's the value of pos_neg_break \n",
    "           # optimize the goods side\n",
    "            _, l, neck, true_false_break, max_pos_dist, min_neg_dist, pred_train, neck_dis = sess.run([optimizer_g, loss, loss_neck_distance, threshold, furthest_positive, closest_negative, neck_pred, neck_distance],  \n",
    "                                                        #{optimizer:_, loss:l, loss_neck_distance:neck, threshold:true_false_break, furthest_positive:max_pos_dist, closest_negative:min_neg_dist, neck_pred:pred_train}\n",
    "                                                        feed_dict={X: Xtrain[batch], label: Ytrain[batch], training: True, pos_neg_break: 0}) # because it is training, it doesn't matter what's the value of pos_neg_break \n",
    "            #print(l)\n",
    "            \"\"\"print(Xtrain[batch][0])\n",
    "            print(Ytrain[batch][0])\"\"\"\n",
    "            \n",
    "            avg_train_cost += l\n",
    "            avg_train_neck_cost += neck\n",
    "            avg_auc += roc_auc_score(Ytrain[batch], pred_train) # adding training batch training auc score\n",
    "        \n",
    "        avg_train_cost /= num_train_batches\n",
    "        avg_train_neck_cost /= num_train_batches\n",
    "        avg_auc /= num_train_batches # averaging out training batch auc score\n",
    "        \n",
    "        \"\"\"print(Xval[0])\n",
    "        print(Yval[0])\"\"\"\n",
    "        \n",
    "        # Validate once an epoch ends\n",
    "        val_cost, val_neck_cost, pred_val, neck_dis_val = sess.run([loss, loss_neck_distance, neck_pred, neck_distance], # {loss:val_cost, loss_neck_distance:val_neck_cost, neck_pred:pred_val}\n",
    "                                                    feed_dict={X: Xval, label: Yval, training: False, pos_neg_break: true_false_break})\n",
    "        val_auc = roc_auc_score(Yval, pred_val) # getting validation auc score\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            if i >= 100:            \n",
    "                # look at the training metric space\n",
    "                signed = np.multiply(neck_dis.flatten(), 2*Ytrain[batch].flatten()-1)\n",
    "                pos = []\n",
    "                neg = []\n",
    "                for dist in signed:\n",
    "                    if dist >= 0:\n",
    "                        pos.append(dist)\n",
    "                    else:\n",
    "                        neg.append(dist)\n",
    "\n",
    "                plt.figure(figsize=(12, 4))\n",
    "                pos = np.array(pos)\n",
    "                neg = np.array(neg)\n",
    "\n",
    "                a = np.mean(pos)\n",
    "                b = np.mean(neg)\n",
    "            \n",
    "                sns.set(color_codes=True)\n",
    "                sns.distplot(pos, bins=20, kde = False, color=\"r\", label=\"red: pos dis\")\n",
    "                sns.distplot(-neg, bins=20, kde = False , color=\"b\", label=\"blue: neg dis\")\n",
    "                plt.legend()\n",
    "                plt.xlim(0, math.sqrt(num_neck))\n",
    "                plt.show()\n",
    "                \n",
    "                # look at the validation metric space\n",
    "                signed_val = np.multiply(neck_dis_val.flatten(), 2*Yval.flatten()-1)\n",
    "                pos_val = []\n",
    "                neg_val = []\n",
    "                for dist_val in signed_val:\n",
    "                    if dist_val >= 0:\n",
    "                        pos_val.append(dist_val)\n",
    "                    else:\n",
    "                        neg_val.append(dist_val)\n",
    "\n",
    "                plt.figure(figsize=(12, 4))\n",
    "                pos_val = np.array(pos_val)\n",
    "                neg_val = np.array(neg_val)\n",
    "\n",
    "                a_val = np.mean(pos_val)\n",
    "                b_val = np.mean(neg_val)\n",
    "            \n",
    "                sns.set(color_codes=True)\n",
    "                sns.distplot(pos_val, bins=20, kde = False, color=\"r\", label=\"red: pos dis\")\n",
    "                sns.distplot(-neg_val, bins=20, kde = False , color=\"b\", label=\"blue: neg dis\")\n",
    "                plt.legend()\n",
    "                plt.xlim(0, math.sqrt(num_neck))\n",
    "                plt.show()\n",
    "                \n",
    "            true_false_break = math.sqrt(num_neck) / 2\n",
    "            \n",
    "            print(\"Epoch: {:>3} | Train Loss: {:+8.2f} | Val Loss: {:+8.3f} | Train Neck: {:+13.8f} | Val Neck: {:+8.3f} | Train AUC: {:+8.3f} | Val AUC: {:+8.3f} | TF Break: {:06.3f} | mean pos dist: {:06.3f} | mean neg dist {:06.3f} \"\n",
    "                  .format( i + 1,        avg_train_cost, val_cost,     avg_train_neck_cost, val_neck_cost,   avg_auc,val_auc,   true_false_break, a, -b)) # ORIGINAL: {max_pos_dist : a, min_neg_dist : -b}\n",
    "            \n",
    "    Ytest = np.reshape(Ytest, [-1,1])\n",
    "\n",
    "        \n",
    "    # Testing\n",
    "    test_cost, test_neck_cost, pred_test = sess.run([loss, loss_neck_distance, neck_pred],  # {loss:test_cost, loss_neck_distance:test_neck_cost, neck_pred:pred_test}\n",
    "                                                   feed_dict={X: Xtest, label: Ytest, training: False, pos_neg_break: true_false_break})\n",
    "    test_auc = roc_auc_score(Ytest, pred_test)  # getting testing auc score\n",
    "    print(\"Test Loss: {:02.5f} | Neck Loss: {:02.5f} | AUC: {:02.5f}\".format(test_cost, test_neck_cost, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Compressed Sensing to hash high dimensional sparse binary feature group into numerical low dimensional representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sparse feature group begin and ending column indecies\n",
    "user_sparse_feat = [\"user_gender_0\", \"user_7_hero_0\", \"user_30_hero_0\", \"user_7_keyword_0\", \"user_7_author_0\", \"item_rate\"]\n",
    "item_sparse_feat = [\"item_keyword_0\", \"item_author_0\", \"item_avgTime\"] \n",
    "\n",
    "user_sparse_feat_beginEnd = []\n",
    "item_sparse_feat_beginEnd = []\n",
    "\n",
    "for i in range(len(user_sparse_feat)-1):\n",
    "    begin = raw.columns.values.tolist().index(user_sparse_feat[i])\n",
    "    end = raw.columns.values.tolist().index(user_sparse_feat[i+1])-1\n",
    "    user_sparse_feat_beginEnd.append((begin, end))\n",
    "    \n",
    "for i in range(len(item_sparse_feat)-1):\n",
    "    begin = raw.columns.values.tolist().index(item_sparse_feat[i])\n",
    "    end = raw.columns.values.tolist().index(item_sparse_feat[i+1])-1\n",
    "    item_sparse_feat_beginEnd.append((begin, end))\n",
    "    \n",
    "print(\"user sparse feature begin end index:\", str(user_sparse_feat_beginEnd))\n",
    "print(\"item sparse feature begin end index:\", str(item_sparse_feat_beginEnd))\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Emmanuelle Gouillart <emmanuelle.gouillart@nsup.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _weights(x, dx=1, orig=0):\n",
    "    x = np.ravel(x)\n",
    "    floor_x = np.floor((x - orig) / dx).astype(np.int64)\n",
    "    alpha = (x - orig - floor_x * dx) / dx\n",
    "    return np.hstack((floor_x, floor_x + 1)), np.hstack((1 - alpha, alpha))\n",
    "\n",
    "\n",
    "def _generate_center_coordinates(l_x):\n",
    "    X, Y = np.mgrid[:l_x, :l_x].astype(np.float64)\n",
    "    center = l_x / 2.\n",
    "    X += 0.5 - center\n",
    "    Y += 0.5 - center\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def build_projection_operator(l_x, n_dir):\n",
    "    \"\"\" Compute the tomography design matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    l_x : int\n",
    "        linear size of image array\n",
    "\n",
    "    n_dir : int\n",
    "        number of angles at which projections are acquired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p : sparse matrix of shape (n_dir l_x, l_x**2)\n",
    "    \"\"\"\n",
    "    X, Y = _generate_center_coordinates(l_x)\n",
    "    angles = np.linspace(0, np.pi, n_dir, endpoint=False)\n",
    "    data_inds, weights, camera_inds = [], [], []\n",
    "    data_unravel_indices = np.arange(l_x ** 2)\n",
    "    data_unravel_indices = np.hstack((data_unravel_indices,\n",
    "                                      data_unravel_indices))\n",
    "    for i, angle in enumerate(angles):\n",
    "        Xrot = np.cos(angle) * X - np.sin(angle) * Y\n",
    "        inds, w = _weights(Xrot, dx=1, orig=X.min())\n",
    "        mask = np.logical_and(inds >= 0, inds < l_x)\n",
    "        weights += list(w[mask])\n",
    "        camera_inds += list(inds[mask] + i * l_x)\n",
    "        data_inds += list(data_unravel_indices[mask])\n",
    "    proj_operator = sparse.coo_matrix((weights, (camera_inds, data_inds)))\n",
    "    return proj_operator\n",
    "\n",
    "\n",
    "def generate_synthetic_data():\n",
    "    \"\"\" Synthetic binary data \"\"\"\n",
    "    rs = np.random.RandomState(0)\n",
    "    n_pts = 36\n",
    "    x, y = np.ogrid[0:l, 0:l]\n",
    "    mask_outer = (x - l / 2.) ** 2 + (y - l / 2.) ** 2 < (l / 2.) ** 2\n",
    "    mask = np.zeros((l, l))\n",
    "    points = l * rs.rand(2, n_pts)\n",
    "    mask[(points[0]).astype(np.int), (points[1]).astype(np.int)] = 1\n",
    "    mask = ndimage.gaussian_filter(mask, sigma=l / n_pts)\n",
    "    res = np.logical_and(mask > mask.mean(), mask_outer)\n",
    "    return np.logical_xor(res, ndimage.binary_erosion(res))\n",
    "\n",
    "\n",
    "# Generate synthetic images, and projections\n",
    "l = 128\n",
    "proj_operator = build_projection_operator(l, l // 2)\n",
    "data = generate_synthetic_data()\n",
    "\n",
    "\n",
    "proj = proj_operator * data.ravel()[:, np.newaxis]\n",
    "proj += 0.15 * np.random.randn(*proj.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruction with L1 (Lasso) penalization\n",
    "# the best value of alpha was determined using cross validation\n",
    "# with LassoCV\n",
    "rgr_lasso = Lasso(alpha=0.001)\n",
    "rgr_lasso.fit(proj_operator, proj.ravel())\n",
    "rec_l1 = rgr_lasso.coef_.reshape(l, l)\n",
    "\n",
    "plt.figure(figsize=(8, 3.3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(data, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('original image')\n",
    "plt.subplot(132)\n",
    "\n",
    "plt.imshow(rec_l1, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.title('L1 penalization')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01, top=1, bottom=0, left=0,\n",
    "                    right=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop(columns='label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuck_true = np.array([0, 0, 1, 1])\n",
    "fuck_scores = np.array([False, False, False, True])\n",
    "roc_auc_score(fuck_true, fuck_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "\n",
    "iris = load_iris()\n",
    "iris = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                    columns=iris['feature_names'] + ['target'])\n",
    "\n",
    "# Sort the dataframe by target\n",
    "target_0 = iris.loc[iris['target'] == 0]\n",
    "target_1 = iris.loc[iris['target'] == 1]\n",
    "target_2 = iris.loc[iris['target'] == 2]\n",
    "\n",
    "sns.distplot(pos, hist=False, kde_kws={\"shade\": True})\n",
    "sns.distplot(neg, hist=False, kde_kws={\"shade\": True})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.446"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  1.78813920e-07,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.78813920e-07, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  8.94069601e-08,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  2.38418565e-07, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        1.19209282e-07, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  2.98023206e-08,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        6.66400197e-08,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  4.37231665e-06,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        8.94069601e-08,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        2.98023206e-08, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  1.19209282e-07,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  8.81850647e-05,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  2.40273977e-07, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
