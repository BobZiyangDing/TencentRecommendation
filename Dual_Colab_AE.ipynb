{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-Collaborative Filtering Autoencoder Metric Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziyangding\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\ziyangding\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\ziyangding\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\ziyangding\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\ziyangding\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "def sparseEmbed(df, name, num, colIdx):\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)] \n",
    "    Emptydf = pd.DataFrame()\n",
    "    Emptydf[embedName] = df[name].str.split('|',expand=True)\n",
    "    values = np.unique(Emptydf[embedName].values)\n",
    "    \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in values:\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "    \n",
    "    \n",
    "    appendValue = np.zeros([Emptydf.values.shape[0], len(values)])\n",
    "    for i in range(Emptydf.values.shape[0]):\n",
    "        for j in range(num):\n",
    "            key = Emptydf.values[i][j]\n",
    "            if key in dic:\n",
    "                appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df\n",
    "\n",
    "def toDummy(df, name, colIdx):\n",
    "    num = len(np.unique(df[name].values.astype(str)))-1\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)]  # don't need nan value\n",
    "        \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in range(num+1):\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "        \n",
    "    appendValue = np.zeros([df[name].size, a])\n",
    "    for i in range(df[name].size):\n",
    "        key = df[name].values[i]\n",
    "        if key in dic:\n",
    "            appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df\n",
    "\n",
    "def genderDummy(df, name, colIdx):\n",
    "    pool = set()\n",
    "    num = len(np.unique(df[name].values))-1\n",
    "    for i in df[name].values:\n",
    "        pool.add(str(i))\n",
    "    num = len(list(pool))-1\n",
    "    embedName = [ name+\"_\"+str(i) for i in range(num)]  # don't need nan value\n",
    "        \n",
    "    dic = {}\n",
    "    a = 0\n",
    "    for i in range(num+1):\n",
    "        dic[i] = a\n",
    "        a += 1\n",
    "    dic.pop('nan', None)\n",
    "        \n",
    "    appendValue = np.zeros([df[name].size, a])\n",
    "    for i in range(df[name].size):\n",
    "        key = df[name].values[i]\n",
    "        if key in dic:\n",
    "            appendValue[i][dic[key]] = 1\n",
    "    \n",
    "    for i in range(appendValue.shape[1], 0, -1):\n",
    "        df.insert(colIdx, name+\"_\"+str(i-1), appendValue[:, i-1])\n",
    "    \n",
    "    del df[name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data and transforming to categorical binary input data form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with user_7_hero\n",
      "finished with user_30_hero\n",
      "finished with user_7_keyword\n",
      "finished with user_7_author\n",
      "finished with item_author\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_gender_0</th>\n",
       "      <th>user_gender_1</th>\n",
       "      <th>user_gender_2</th>\n",
       "      <th>user_gender_3</th>\n",
       "      <th>user_7_hero_0</th>\n",
       "      <th>user_7_hero_1</th>\n",
       "      <th>user_7_hero_2</th>\n",
       "      <th>user_7_hero_3</th>\n",
       "      <th>user_7_hero_4</th>\n",
       "      <th>user_7_hero_5</th>\n",
       "      <th>user_7_hero_6</th>\n",
       "      <th>user_7_hero_7</th>\n",
       "      <th>user_7_hero_8</th>\n",
       "      <th>user_7_hero_9</th>\n",
       "      <th>user_7_hero_10</th>\n",
       "      <th>user_7_hero_11</th>\n",
       "      <th>user_7_hero_12</th>\n",
       "      <th>user_7_hero_13</th>\n",
       "      <th>user_7_hero_14</th>\n",
       "      <th>user_7_hero_15</th>\n",
       "      <th>user_7_hero_16</th>\n",
       "      <th>user_7_hero_17</th>\n",
       "      <th>user_7_hero_18</th>\n",
       "      <th>user_7_hero_19</th>\n",
       "      <th>user_7_hero_20</th>\n",
       "      <th>user_7_hero_21</th>\n",
       "      <th>user_7_hero_22</th>\n",
       "      <th>user_7_hero_23</th>\n",
       "      <th>user_7_hero_24</th>\n",
       "      <th>user_7_hero_25</th>\n",
       "      <th>user_7_hero_26</th>\n",
       "      <th>user_7_hero_27</th>\n",
       "      <th>user_7_hero_28</th>\n",
       "      <th>user_7_hero_29</th>\n",
       "      <th>user_7_hero_30</th>\n",
       "      <th>user_7_hero_31</th>\n",
       "      <th>user_7_hero_32</th>\n",
       "      <th>user_7_hero_33</th>\n",
       "      <th>user_7_hero_34</th>\n",
       "      <th>user_7_hero_35</th>\n",
       "      <th>user_7_hero_36</th>\n",
       "      <th>user_7_hero_37</th>\n",
       "      <th>user_7_hero_38</th>\n",
       "      <th>user_7_hero_39</th>\n",
       "      <th>user_7_hero_40</th>\n",
       "      <th>user_7_hero_41</th>\n",
       "      <th>user_7_hero_42</th>\n",
       "      <th>user_7_hero_43</th>\n",
       "      <th>user_7_hero_44</th>\n",
       "      <th>user_7_hero_45</th>\n",
       "      <th>user_7_hero_46</th>\n",
       "      <th>user_7_hero_47</th>\n",
       "      <th>user_7_hero_48</th>\n",
       "      <th>user_7_hero_49</th>\n",
       "      <th>user_7_hero_50</th>\n",
       "      <th>user_7_hero_51</th>\n",
       "      <th>user_7_hero_52</th>\n",
       "      <th>user_7_hero_53</th>\n",
       "      <th>user_7_hero_54</th>\n",
       "      <th>user_7_hero_55</th>\n",
       "      <th>user_7_hero_56</th>\n",
       "      <th>user_7_hero_57</th>\n",
       "      <th>user_7_hero_58</th>\n",
       "      <th>user_7_hero_59</th>\n",
       "      <th>user_7_hero_60</th>\n",
       "      <th>user_7_hero_61</th>\n",
       "      <th>user_7_hero_62</th>\n",
       "      <th>user_7_hero_63</th>\n",
       "      <th>user_7_hero_64</th>\n",
       "      <th>user_7_hero_65</th>\n",
       "      <th>user_7_hero_66</th>\n",
       "      <th>user_7_hero_67</th>\n",
       "      <th>user_7_hero_68</th>\n",
       "      <th>user_7_hero_69</th>\n",
       "      <th>user_7_hero_70</th>\n",
       "      <th>user_7_hero_71</th>\n",
       "      <th>user_7_hero_72</th>\n",
       "      <th>user_7_hero_73</th>\n",
       "      <th>user_7_hero_74</th>\n",
       "      <th>user_7_hero_75</th>\n",
       "      <th>user_7_hero_76</th>\n",
       "      <th>user_7_hero_77</th>\n",
       "      <th>user_7_hero_78</th>\n",
       "      <th>user_7_hero_79</th>\n",
       "      <th>user_7_hero_80</th>\n",
       "      <th>user_7_hero_81</th>\n",
       "      <th>user_7_hero_82</th>\n",
       "      <th>user_7_hero_83</th>\n",
       "      <th>user_7_hero_84</th>\n",
       "      <th>user_7_hero_85</th>\n",
       "      <th>user_7_hero_86</th>\n",
       "      <th>user_7_hero_87</th>\n",
       "      <th>user_7_hero_88</th>\n",
       "      <th>user_7_hero_89</th>\n",
       "      <th>user_7_hero_90</th>\n",
       "      <th>user_7_hero_91</th>\n",
       "      <th>user_7_hero_92</th>\n",
       "      <th>user_7_hero_93</th>\n",
       "      <th>user_7_hero_94</th>\n",
       "      <th>user_7_hero_95</th>\n",
       "      <th>user_7_hero_96</th>\n",
       "      <th>user_7_hero_97</th>\n",
       "      <th>user_7_hero_98</th>\n",
       "      <th>...</th>\n",
       "      <th>item_author_425</th>\n",
       "      <th>item_author_426</th>\n",
       "      <th>item_author_427</th>\n",
       "      <th>item_author_428</th>\n",
       "      <th>item_author_429</th>\n",
       "      <th>item_author_430</th>\n",
       "      <th>item_author_431</th>\n",
       "      <th>item_author_432</th>\n",
       "      <th>item_author_433</th>\n",
       "      <th>item_author_434</th>\n",
       "      <th>item_author_435</th>\n",
       "      <th>item_author_436</th>\n",
       "      <th>item_author_437</th>\n",
       "      <th>item_author_438</th>\n",
       "      <th>item_author_439</th>\n",
       "      <th>item_author_440</th>\n",
       "      <th>item_author_441</th>\n",
       "      <th>item_author_442</th>\n",
       "      <th>item_author_443</th>\n",
       "      <th>item_author_444</th>\n",
       "      <th>item_author_445</th>\n",
       "      <th>item_author_446</th>\n",
       "      <th>item_author_447</th>\n",
       "      <th>item_author_448</th>\n",
       "      <th>item_author_449</th>\n",
       "      <th>item_author_450</th>\n",
       "      <th>item_author_451</th>\n",
       "      <th>item_author_452</th>\n",
       "      <th>item_author_453</th>\n",
       "      <th>item_author_454</th>\n",
       "      <th>item_author_455</th>\n",
       "      <th>item_author_456</th>\n",
       "      <th>item_author_457</th>\n",
       "      <th>item_author_458</th>\n",
       "      <th>item_author_459</th>\n",
       "      <th>item_author_460</th>\n",
       "      <th>item_author_461</th>\n",
       "      <th>item_author_462</th>\n",
       "      <th>item_author_463</th>\n",
       "      <th>item_author_464</th>\n",
       "      <th>item_author_465</th>\n",
       "      <th>item_author_466</th>\n",
       "      <th>item_author_467</th>\n",
       "      <th>item_author_468</th>\n",
       "      <th>item_author_469</th>\n",
       "      <th>item_author_470</th>\n",
       "      <th>item_author_471</th>\n",
       "      <th>item_author_472</th>\n",
       "      <th>item_author_473</th>\n",
       "      <th>item_author_474</th>\n",
       "      <th>item_author_475</th>\n",
       "      <th>item_author_476</th>\n",
       "      <th>item_author_477</th>\n",
       "      <th>item_author_478</th>\n",
       "      <th>item_author_479</th>\n",
       "      <th>item_author_480</th>\n",
       "      <th>item_author_481</th>\n",
       "      <th>item_author_482</th>\n",
       "      <th>item_author_483</th>\n",
       "      <th>item_author_484</th>\n",
       "      <th>item_author_485</th>\n",
       "      <th>item_author_486</th>\n",
       "      <th>item_author_487</th>\n",
       "      <th>item_author_488</th>\n",
       "      <th>item_author_489</th>\n",
       "      <th>item_author_490</th>\n",
       "      <th>item_author_491</th>\n",
       "      <th>item_author_492</th>\n",
       "      <th>item_author_493</th>\n",
       "      <th>item_author_494</th>\n",
       "      <th>item_author_495</th>\n",
       "      <th>item_author_496</th>\n",
       "      <th>item_author_497</th>\n",
       "      <th>item_author_498</th>\n",
       "      <th>item_author_499</th>\n",
       "      <th>item_author_500</th>\n",
       "      <th>item_author_501</th>\n",
       "      <th>item_author_502</th>\n",
       "      <th>item_author_503</th>\n",
       "      <th>item_author_504</th>\n",
       "      <th>item_author_505</th>\n",
       "      <th>item_author_506</th>\n",
       "      <th>item_author_507</th>\n",
       "      <th>item_author_508</th>\n",
       "      <th>item_author_509</th>\n",
       "      <th>item_author_510</th>\n",
       "      <th>item_author_511</th>\n",
       "      <th>item_author_512</th>\n",
       "      <th>item_author_513</th>\n",
       "      <th>item_author_514</th>\n",
       "      <th>item_author_515</th>\n",
       "      <th>item_author_516</th>\n",
       "      <th>item_author_517</th>\n",
       "      <th>item_author_518</th>\n",
       "      <th>item_author_519</th>\n",
       "      <th>item_author_520</th>\n",
       "      <th>item_author_521</th>\n",
       "      <th>item_author_522</th>\n",
       "      <th>item_author_523</th>\n",
       "      <th>item_author_524</th>\n",
       "      <th>item_avgTime</th>\n",
       "      <th>item_numReader</th>\n",
       "      <th>item_numTime</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319709</th>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135568</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306982</th>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176038</td>\n",
       "      <td>0.115595</td>\n",
       "      <td>0.141602</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84893</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318971</td>\n",
       "      <td>0.335567</td>\n",
       "      <td>0.744827</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131164</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045305</td>\n",
       "      <td>0.585097</td>\n",
       "      <td>0.184460</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87211</th>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157885</td>\n",
       "      <td>0.132271</td>\n",
       "      <td>0.145322</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_age  user_gender_0  user_gender_1  user_gender_2  user_gender_3  user_7_hero_0  user_7_hero_1  ...  item_author_522  item_author_523  item_author_524  item_avgTime  item_numReader  item_numTime  label\n",
       "319709  0.226667            0.0            1.0            0.0            0.0            0.0            0.0  ...              0.0              0.0              0.0      0.135568        0.006500      0.006132    1.0\n",
       "306982  0.346667            0.0            1.0            0.0            0.0            0.0            0.0  ...              0.0              0.0              0.0      0.176038        0.115595      0.141602    0.0\n",
       "84893   0.240000            0.0            0.0            1.0            0.0            0.0            0.0  ...              0.0              0.0              0.0      0.318971        0.335567      0.744827    0.0\n",
       "131164  0.280000            0.0            1.0            0.0            0.0            0.0            0.0  ...              0.0              0.0              0.0      0.045305        0.585097      0.184460    1.0\n",
       "87211   0.306667            0.0            1.0            0.0            0.0            0.0            0.0  ...              0.0              0.0              0.0      0.157885        0.132271      0.145322    1.0\n",
       "\n",
       "[5 rows x 2119 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = [\"user_age\", \"user_gender\", \"user_7_hero\", \"user_30_hero\", \"user_7_keyword\", \"user_7_author\", \"item_rate\", \"item_keyword\", \"item_author\", \"item_avgTime\", \"item_numReader\", \"item_numTime\", \"label\"]\n",
    "raw = pd.read_csv(\"./thing.txt\", names=head, sep=\",\", index_col = False)\n",
    "\n",
    "colIdx = raw.columns.values.tolist().index(\"user_gender\")\n",
    "raw = genderDummy(raw, \"user_gender\", colIdx)\n",
    "colIdx = raw.columns.values.tolist().index(\"item_keyword\")\n",
    "raw = toDummy(raw, \"item_keyword\", colIdx)\n",
    "\n",
    "numDic = {\"user_gender\": 1, \"user_7_hero\": 5, \"user_30_hero\": 5, \"user_7_keyword\": 3, \"user_7_author\": 3, \"item_keyword\": 1, \"item_author\": 3}\n",
    "for i in [\"user_7_hero\", \"user_30_hero\", \"user_7_keyword\", \"user_7_author\", \"item_author\"]:\n",
    "    colIdx = raw.columns.values.tolist().index(i)\n",
    "    raw = sparseEmbed(raw, i, numDic[i], colIdx)\n",
    "    print(\"finished with\", i)\n",
    "\n",
    "# normalize numerical features into interval [0, 1]\n",
    "for i in [\"user_age\", \"item_rate\", \"item_avgTime\", \"item_numReader\", \"item_numTime\"]:\n",
    "    r = raw[i].values.astype(float)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "    raw_normalized = pd.DataFrame(x_scaled)\n",
    "    raw[i] = raw_normalized\n",
    "\n",
    "raw = raw.sample(200000)\n",
    "    \n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = raw.sample(5000)\n",
    "\n",
    "# Splitting dataframe into train, validation, and testing\n",
    "dataY = data['label'].values\n",
    "dataX = data.drop(columns = 'label').values\n",
    "\n",
    "\n",
    "X, Xtest, Y, Ytest = train_test_split(dataX, dataY, test_size = 0.2, random_state = 42)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print(\"training data size: {} | validate data size: {} | testing data size: {}\".format(str(Xtrain.shape), str(Xval.shape), str(Xtest.shape)))\n",
    "\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.000001\n",
    "batch_size = 256\n",
    "epochs = 800\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "num_input = Xtrain.shape[1]\n",
    "num_input_p = data.columns.values.tolist().index(\"item_rate\") # number of all user input columns, the last column ends before the start of \"item_rate\" column\n",
    "num_input_g = data.columns.values.shape[0] - num_input_p - 1   # number of all item input columns, = all column -user -label\n",
    "\n",
    "a = 1\n",
    "num_encode_1 = int(256 *a)\n",
    "num_encode_2 = int(128 *a)\n",
    "num_encode_3 = int(64 *a)\n",
    "\n",
    "\n",
    "num_neck = 5\n",
    "\n",
    "num_decode_1 = num_encode_3\n",
    "num_decode_2 = num_encode_2\n",
    "num_decode_3 = num_encode_1\n",
    "\n",
    "num_output_to_p = num_input_p\n",
    "num_output_to_g = num_input_g\n",
    "\n",
    "#del raw\n",
    "\n",
    "\n",
    "# balance weight coefficient [0,1], the bigger the mode focused onto neck distance\n",
    "alpha = 0.5\n",
    "\n",
    "# regularization\n",
    "beta = 0.0005\n",
    "\n",
    "# collaborative autoencoder input tensor1\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "label = tf.placeholder(\"float\", [None])\n",
    "threshold = tf.Variable(0.0)\n",
    "\n",
    "weights = {\n",
    "    'encoder_ph1': tf.Variable(tf.random_normal([num_input_p , num_encode_1])),\n",
    "    'encoder_gh1': tf.Variable(tf.random_normal([num_input_g , num_encode_1])),\n",
    "    'encoder_ph2': tf.Variable(tf.random_normal([num_encode_1 , num_encode_2])),\n",
    "    'encoder_gh2': tf.Variable(tf.random_normal([num_encode_1 , num_encode_2])),\n",
    "    'encoder_ph3': tf.Variable(tf.random_normal([num_encode_2 , num_encode_3])),\n",
    "    'encoder_gh3': tf.Variable(tf.random_normal([num_encode_2 , num_encode_3])),    \n",
    "\n",
    "\n",
    "    'encoder_pneck': tf.Variable(tf.random_normal([num_encode_3 , num_neck])), ## METRIC SPACE OF PERSON\n",
    "    'encoder_gneck': tf.Variable(tf.random_normal([num_encode_3 , num_neck])), ## METRIC SPACE OF GOODS\n",
    "\n",
    "\n",
    "    'decoder_ph1': tf.Variable(tf.random_normal([num_neck , num_decode_1])),\n",
    "    'decoder_gh1': tf.Variable(tf.random_normal([num_neck , num_decode_1])),\n",
    "    'decoder_ph2': tf.Variable(tf.random_normal([num_decode_1 , num_decode_2])),\n",
    "    'decoder_gh2': tf.Variable(tf.random_normal([num_decode_1 , num_decode_2])),\n",
    "    'decoder_ph3': tf.Variable(tf.random_normal([num_decode_2 , num_decode_3])),\n",
    "    'decoder_gh3': tf.Variable(tf.random_normal([num_decode_2 , num_decode_3])),    \n",
    "\n",
    "\n",
    "    'decoder_p_to_p_out': tf.Variable(tf.random_normal([num_decode_3 , num_output_to_p])),\n",
    "    'decoder_g_to_g_out': tf.Variable(tf.random_normal([num_decode_3 , num_output_to_g]))\n",
    "}\n",
    "\n",
    "biases = {  \n",
    "    'encoder_bph1': tf.Variable(tf.random_normal([num_encode_1])),\n",
    "    'encoder_bgh1': tf.Variable(tf.random_normal([num_encode_1])),\n",
    "    'encoder_bph2': tf.Variable(tf.random_normal([num_encode_2])),\n",
    "    'encoder_bgh2': tf.Variable(tf.random_normal([num_encode_2])),\n",
    "    'encoder_bph3': tf.Variable(tf.random_normal([num_encode_3])),\n",
    "    'encoder_bgh3': tf.Variable(tf.random_normal([num_encode_3])),\n",
    "\n",
    "\n",
    "    'encoder_bpneck': tf.Variable(tf.random_normal([num_neck])), ## METRIC SPACE OF PERSON\n",
    "    'encoder_bgneck': tf.Variable(tf.random_normal([num_neck])), ## METRIC SPACE OF GOODS\n",
    "\n",
    "\n",
    "    'decoder_bph1': tf.Variable(tf.random_normal([num_decode_1])),\n",
    "    'decoder_bgh1': tf.Variable(tf.random_normal([num_decode_1])),\n",
    "    'decoder_bph2': tf.Variable(tf.random_normal([num_decode_2])),\n",
    "    'decoder_bgh2': tf.Variable(tf.random_normal([num_decode_2])),\n",
    "    'decoder_bph3': tf.Variable(tf.random_normal([num_decode_3])),\n",
    "    'decoder_bgh3': tf.Variable(tf.random_normal([num_decode_3])),    \n",
    "\n",
    "\n",
    "    'decoder_b_p_to_p_out': tf.Variable(tf.random_normal([num_output_to_p])),\n",
    "    'decoder_b_g_to_g_out': tf.Variable(tf.random_normal([num_output_to_g]))\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "\n",
    "    ## Person encoder:\n",
    "    layer_p_1 = tf.nn.relu(tf.add(tf.matmul(x[:, :1376], weights['encoder_ph1']), biases['encoder_bph1']))  ## HARD CODING: 1375 is the ending index of person feature; 1376 the starting index of goods feature\n",
    "    layer_p_2 = tf.nn.relu(tf.add(tf.matmul(layer_p_1, weights['encoder_ph2']), biases['encoder_bph2']))\n",
    "    layer_p_3 = tf.nn.relu(tf.add(tf.matmul(layer_p_2, weights['encoder_ph3']), biases['encoder_bph3']))\n",
    "\n",
    "    layer_p_neck = tf.nn.sigmoid(tf.add(tf.matmul(layer_p_3, weights['encoder_pneck']), biases['encoder_bpneck']))\n",
    "\n",
    "    ## Good encoder\n",
    "    layer_g_1 = tf.nn.relu(tf.add(tf.matmul(x[:, 1376:], weights['encoder_gh1']), biases['encoder_bgh1']))  ## HARD CODING: 1375 is the ending index of person feature; 1376 the starting index of goods feature\n",
    "    layer_g_2 = tf.nn.relu(tf.add(tf.matmul(layer_g_1, weights['encoder_gh2']), biases['encoder_bgh2']))\n",
    "    layer_g_3 = tf.nn.relu(tf.add(tf.matmul(layer_g_2, weights['encoder_gh3']), biases['encoder_bgh3']))\n",
    "\n",
    "    layer_g_neck = tf.nn.sigmoid(tf.add(tf.matmul(layer_g_3, weights['encoder_gneck']), biases['encoder_bgneck']))\n",
    "\n",
    "\n",
    "    return layer_p_neck, layer_g_neck\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(p_neck, g_neck):\n",
    "\n",
    "    ## Good to Person decoder\n",
    "    layer_p_1 = tf.nn.relu(tf.add(tf.matmul(p_neck, weights['decoder_ph1']), biases['decoder_bph1']))\n",
    "    layer_p_2 = tf.nn.relu(tf.add(tf.matmul(layer_p_1, weights['decoder_ph2']), biases['decoder_bph2']))\n",
    "    layer_p_3 = tf.nn.relu(tf.add(tf.matmul(layer_p_2, weights['decoder_ph3']), biases['decoder_bph3']))\n",
    "\n",
    "    layer_p_to_p_out = tf.nn.sigmoid(tf.add(tf.matmul(layer_p_3, weights['decoder_p_to_p_out']), biases['decoder_b_p_to_p_out']))\n",
    "\n",
    "\n",
    "\n",
    "    ## Person to Good decoder\n",
    "    layer_g_1 = tf.nn.relu(tf.add(tf.matmul(g_neck, weights['decoder_gh1']), biases['decoder_bgh1']))\n",
    "    layer_g_2 = tf.nn.relu(tf.add(tf.matmul(layer_g_1, weights['decoder_gh2']), biases['decoder_bgh2']))\n",
    "    layer_g_3 = tf.nn.relu(tf.add(tf.matmul(layer_g_2, weights['decoder_gh3']), biases['decoder_bgh3']))\n",
    "\n",
    "    layer_g_to_g_out = tf.nn.sigmoid(tf.add(tf.matmul(layer_g_3, weights['decoder_g_to_g_out']), biases['decoder_b_g_to_g_out']))\n",
    "\n",
    "    result = tf.concat([layer_p_to_p_out, layer_g_to_g_out], axis = 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Construct model\n",
    "\n",
    "encoder_p, encoder_g = encoder(X)\n",
    "decoder_out = decoder(encoder_p, encoder_g)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_out\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "def getl2loss(dic):\n",
    "    l2 = 0\n",
    "    for i in dic.keys():\n",
    "        l2 += tf.nn.l2_loss(dic[i])\n",
    "    return l2\n",
    "\n",
    "sign = 2*label-1\n",
    "\n",
    "\n",
    "# calculate l2 distance\n",
    "neck_distance_l2 = tf.reshape(tf.norm(encoder_p-encoder_g, axis = 1), [-1])\n",
    "signed_distance_l2 = tf.multiply(neck_distance_l2, sign)\n",
    "\n",
    "\n",
    "\n",
    "# calculate l infinity distance\n",
    "neck_distance_linf = tf.reshape(tf.norm(encoder_p - encoder_g, axis=1, ord = np.infty), [-1])\n",
    "signed_distance_linf = tf.multiply(neck_distance_linf, sign)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4 different losses\n",
    "loss_neck_distance = tf.reduce_mean(tf.maximum(0.0, 0.6*threshold+tf.multiply(sign, signed_distance_l2-threshold)))\n",
    "\n",
    "\n",
    "\n",
    "#signed_centered_distance = -(neck_distance - tf.reduce_mean(neck_distance))\n",
    "# loss_neck_distance = tf.losses.hinge_loss(label, tf.multiply(sign, signed_distance_linf-threshold))\n",
    "loss_pred_distance = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "loss_weights = tf.reduce_sum(getl2loss(weights))\n",
    "loss_bias = tf.reduce_sum(getl2loss(biases))\n",
    "\n",
    "loss = alpha * loss_neck_distance + (1-alpha) * loss_pred_distance + beta * (loss_weights + loss_bias)\n",
    "\n",
    "\n",
    "# Calculating AUC: \n",
    "# NOTE: because threshold is always half of maximum distance, \n",
    "# 2*threshold is maximum distance, normalize to scale of 1\n",
    "# then use 1 to minus will yield a inversion that matches distance proximity property\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "auc, _ = tf.metrics.auc(label, tf.cast(tf.less_equal(neck_distance_linf, threshold,), tf.int32  ) )\n",
    "\n",
    "\n",
    "# Define Optimizer\n",
    "p_var_list = [weights[\"encoder_ph1\"], weights[\"encoder_ph2\"], weights[\"encoder_ph3\"], weights[\"encoder_pneck\"], \n",
    "              weights[\"decoder_ph1\"], weights[\"decoder_ph2\"], weights[\"decoder_ph3\"], weights[\"decoder_p_to_p_out\"],\n",
    "              biases[\"encoder_bph1\"], biases[\"encoder_bph2\"], biases[\"encoder_bph3\"], biases[\"encoder_bpneck\"], \n",
    "              biases[\"decoder_bph1\"], biases[\"decoder_bph2\"], biases[\"decoder_bph3\"], biases[\"decoder_b_p_to_p_out\"]]\n",
    "\n",
    "g_var_list = [weights[\"encoder_gh1\"], weights[\"encoder_gh2\"], weights[\"encoder_gh3\"], weights[\"encoder_gneck\"], \n",
    "              weights[\"decoder_gh1\"], weights[\"decoder_gh2\"], weights[\"decoder_gh3\"], weights[\"decoder_g_to_g_out\"],\n",
    "              biases[\"encoder_bgh1\"], biases[\"encoder_bgh2\"], biases[\"encoder_bgh3\"], biases[\"encoder_bgneck\"], \n",
    "              biases[\"decoder_bgh1\"], biases[\"decoder_bgh2\"], biases[\"decoder_bgh3\"], biases[\"decoder_b_g_to_g_out\"]]\n",
    "\n",
    "optimizer_p = tf.train.RMXPropOptimizer(learning_rate).minimize(loss, var_list = p_var_list)\n",
    "optimizer_g = tf.train.RMXPropOptimizer(learning_rate).minimize(loss, var_list = g_var_list)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "local_init = tf.local_variables_initializer()\n",
    "\n",
    "\n",
    "# Start Training\n",
    "# Start a new TF session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    sess.run(local_init)\n",
    "\n",
    "\n",
    "    num_train_batches = int(Xtrain.shape[0] / batch_size)\n",
    "    Xtrain = np.array_split(Xtrain, num_train_batches)\n",
    "    Ytrain = np.array_split(Ytrain, num_train_batches)\n",
    "\n",
    "    for i in range(len(Ytrain)):\n",
    "        Ytrain[i] = np.reshape(Ytrain[i], [-1,1])\n",
    "    Yval = np.reshape(Yval, [-1,1])\n",
    "\n",
    "\n",
    "\n",
    "    # Training with validating\n",
    "    true_false_break = math.sqrt(num_neck)/2\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_train_cost = 0\n",
    "        avg_train_neck_cost = 0\n",
    "        avg_train_pred_cost = 0\n",
    "        avg_train_auc =0\n",
    "        for batch in range(len(Xtrain)):\n",
    "\n",
    "            # optimize the person side\n",
    "            _, l, neck_loss, pred_loss, neck_dis_train, train_auc = sess.run([optimizer_p, loss, loss_neck_distance, loss_pred_distance, neck_distance_l2, auc],  \n",
    "                                                        #{optimizer:_, loss:l, loss_neck_distance:neck_loss, loss_pred_distance:pred_loss, neck_distance_l2:neck_dis}\n",
    "                                                        feed_dict={X: Xtrain[batch], label: np.reshape(Ytrain[batch], [-1]), threshold: true_false_break})\n",
    "           # optimize the goods side\n",
    "            _, l, neck_loss, pred_loss, neck_dis_train, train_auc = sess.run([optimizer_g, loss, loss_neck_distance, loss_pred_distance, neck_distance_l2, auc],  \n",
    "                                                        #{optimizer:_, loss:l, loss_neck_distance:neck_loss, loss_pred_distance:pred_loss, neck_distance_l2:neck_dis}\n",
    "                                                        feed_dict={X: Xtrain[batch], label: np.reshape(Ytrain[batch], [-1]), threshold: true_false_break})\n",
    "\n",
    "            avg_train_cost += l\n",
    "            avg_train_neck_cost += neck_loss\n",
    "            avg_train_pred_cost += pred_loss\n",
    "            avg_train_auc += train_auc\n",
    "\n",
    "            \n",
    "        avg_train_cost /= num_train_batches\n",
    "        avg_train_neck_cost /= num_train_batches\n",
    "        avg_train_pred_cost /= num_train_batches\n",
    "        avg_train_auc /= num_train_batches \n",
    "            \n",
    "\n",
    "        # Validate once an epoch ends\n",
    "        val_cost, val_neck_cost, val_pred_loss, neck_dis_val, val_auc = sess.run([loss, loss_neck_distance, loss_pred_distance, neck_distance_l2, auc],  \n",
    "                                                        #{optimizer:_, loss:l, loss_neck_distance:neck_loss, loss_pred_distance:pred_loss, neck_distance_l2:neck_dis}\n",
    "                                                        feed_dict={X: Xval, label: np.reshape(Yval, [-1]), threshold: true_false_break})\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            # look at the training metric space\n",
    "            signed_train = np.multiply(neck_dis_train, 2*Ytrain[batch].flatten()-1)\n",
    "            pos = []\n",
    "            neg = []\n",
    "            for dist in signed_train:\n",
    "                if dist >= 0:\n",
    "                    pos.append(dist)\n",
    "                else:\n",
    "                    neg.append(dist)\n",
    "\n",
    "\n",
    "            pos = np.array(pos)\n",
    "            neg = np.array(neg)\n",
    "\n",
    "            a = np.mean(pos)\n",
    "            b = np.mean(neg)\n",
    "\n",
    "\n",
    "            # look at the validation metric space\n",
    "            signed_val = np.multiply(neck_dis_val.flatten(), 2*Yval.flatten()-1)\n",
    "            pos_val = []\n",
    "            neg_val = []\n",
    "            for dist_val in signed_val:\n",
    "                if dist_val >= 0:\n",
    "                    pos_val.append(dist_val)\n",
    "                else:\n",
    "                    neg_val.append(dist_val)\n",
    "\n",
    "            pos_val = np.array(pos_val)\n",
    "            neg_val = np.array(neg_val)\n",
    "\n",
    "            a_val = np.mean(pos_val)\n",
    "            b_val = np.mean(neg_val)\n",
    "\n",
    "\n",
    "            if i >= 2000:\n",
    "                plt.figure(figsize=(12, 4))\n",
    "                sns.set(color_codes=True)\n",
    "                sns.distplot(pos, bins=20, kde = False, color=\"r\", label=\"red: pos dis\")\n",
    "                sns.distplot(-neg, bins=20, kde = False , color=\"b\", label=\"blue: neg dis\")\n",
    "                plt.legend()\n",
    "                plt.xlim(0, 1)\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure(figsize=(12, 4))\n",
    "                sns.set(color_codes=True)\n",
    "                sns.distplot(pos_val, bins=20, kde = False, color=\"r\", label=\"red: pos dis\")\n",
    "                sns.distplot(-neg_val, bins=20, kde = False , color=\"b\", label=\"blue: neg dis\")\n",
    "                plt.legend()\n",
    "                plt.xlim(0, 1)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            print(\"Epoch: {:>3} | Train Loss: {:+8.2f} | Val Loss: {:+8.3f} | Train Neck: {:+8.3f} | Val Neck: {:+8.3f} | Train Recon: {:+8.3f} | Val Recon: {:+8.3f}\"\n",
    "                  .format( i + 1,    avg_train_cost,         val_cost,        avg_train_neck_cost,      val_neck_cost,       avg_train_pred_cost,    val_pred_loss))\n",
    "            print(\"---------- | Train AUC: {:+8.3f} | Val AUC: {:+8.3f} | TF Break: {:06.3f} | mean pos dist: {:06.3f} | mean neg dist {:06.3f} \"\n",
    "                  .format(avg_train_auc,val_auc,   true_false_break, a, -b))\n",
    "            print()\n",
    "\n",
    "    Ytest = np.reshape(Ytest, [-1,1])\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    test_cost, test_neck_cost, pred_test = sess.run([loss, loss_neck_distance, neck_pred],  # {loss:test_cost, loss_neck_distance:test_neck_cost, neck_pred:pred_test}\n",
    "                                                   feed_dict={X: Xtest, label: Ytest, training: False, pos_neg_break: true_false_break})\n",
    "    test_auc = roc_auc_score(Ytest, pred_test)  # getting testing auc score\n",
    "    print(\"Test Loss: {:02.5f} | Neck Loss: {:02.5f} | AUC: {:02.5f}\".format(test_cost, test_neck_cost, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Subtract, Lambda, Concatenate, multiply\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "\n",
    "batch = 512\n",
    "\n",
    "data = raw.sample(5000)\n",
    "\n",
    "# Splitting dataframe into train, validation, and testing\n",
    "dataY = data['label'].values\n",
    "dataX = data.drop(columns = 'label').values\n",
    "\n",
    "\n",
    "X, Xtest, Y, Ytest = train_test_split(dataX, dataY, test_size = 0.2, random_state = 42)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "\n",
    "break_index = data.columns.values.tolist().index(\"item_rate\") # first item index-1 is the break index\n",
    "length_total = data.values.shape[1]\n",
    "length_p = break_index # index of last user feature into length of the user feature\n",
    "length_g = length_total-length_p-1\n",
    "\n",
    "\n",
    "def pgSplit(data, idx):\n",
    "    data_p = data[:, :idx]\n",
    "    data_g = data[:, idx:]\n",
    "    return data_p, data_g\n",
    "\n",
    "Xtrain_p, Xtrain_g = pgSplit(Xtrain, break_index)\n",
    "Xval_p, Xval_g = pgSplit(Xval, break_index)\n",
    "Xtest_p, Xtest_g = pgSplit(Xtest, break_index)\n",
    "\n",
    "a = 1\n",
    "global num_encode_1\n",
    "global num_encode_2\n",
    "global num_encode_3\n",
    "global num_neck\n",
    "global num_decode_1\n",
    "global num_decode_2\n",
    "global num_decode_3\n",
    "global num_output_to_p\n",
    "global num_output_to_g\n",
    "global threshold\n",
    "\n",
    "num_encode_1 = int(256 *a)\n",
    "num_encode_2 = int(128 *a)\n",
    "num_encode_3 = int(64 *a)\n",
    "num_neck = 100\n",
    "num_decode_1 = num_encode_3\n",
    "num_decode_2 = num_encode_2\n",
    "num_decode_3 = num_encode_1\n",
    "num_output_to_p = length_p\n",
    "num_output_to_g = length_g\n",
    "threshold = 0.5 * math.sqrt(num_neck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Input(shape=(1,))\n",
    "\n",
    "## person autoencoder\n",
    "main_p_input = Input(shape=(length_p,))\n",
    "encode_p_1 = Dense(num_encode_1, activation='relu')(Dropout(0.1)(main_p_input))\n",
    "encode_p_2 = Dense(num_encode_2, activation='relu')(Dropout(0.1)(encode_p_1))\n",
    "encode_p_3 = Dense(num_encode_3, activation='relu')(Dropout(0.1)(encode_p_2))\n",
    "encode_p_neck = Dense(num_neck, activation= 'sigmoid')(encode_p_3) ###\n",
    "decode_p_1 = Dense(num_decode_1, activation='relu')(Dropout(0.1)(encode_p_neck))\n",
    "decode_p_2 = Dense(num_decode_2, activation='relu')(Dropout(0.1)(decode_p_1))\n",
    "decode_p_3 = Dense(num_decode_3, activation='relu')(Dropout(0.1)(decode_p_2))\n",
    "\n",
    "## goods autoencoder\n",
    "main_g_input = Input(shape=(length_g,))\n",
    "encode_g_1 = Dense(num_encode_1, activation='relu')(Dropout(0.1)(main_g_input))\n",
    "encode_g_2 = Dense(num_encode_2, activation='relu')(Dropout(0.1)(encode_g_1))\n",
    "encode_g_3 = Dense(num_encode_3, activation='relu')(Dropout(0.1)(encode_g_2))\n",
    "encode_g_neck = Dense(num_neck, activation= 'sigmoid')(encode_g_3) ###\n",
    "decode_g_1 = Dense(num_decode_1, activation='relu')(Dropout(0.1)(encode_g_neck))\n",
    "decode_g_2 = Dense(num_decode_2, activation='relu')(Dropout(0.1)(decode_g_1))\n",
    "decode_g_3 = Dense(num_decode_3, activation='relu')(Dropout(0.1)(decode_g_2))\n",
    "\n",
    "\n",
    "\n",
    "###### Define 4 output layers\n",
    "# Reconstruction Layer person\n",
    "output_p_out = Dense(num_output_to_p, activation= 'sigmoid', name = \"recon_p\")(decode_p_3)\n",
    "\n",
    "# Reconstruction Layer goods\n",
    "output_g_out = Dense(num_output_to_g, activation= 'sigmoid', name = \"recon_g\")(decode_g_3)\n",
    "\n",
    "# Covariance Layer\n",
    "def CovLayer(X):\n",
    "    n_rows = tf.cast(tf.shape(X)[0], tf.float32)\n",
    "    X = X - (tf.reduce_mean(X, axis=0))\n",
    "    cov = tf.matmul(X, X, transpose_a=True) / n_rows\n",
    "    return tf.reshape(tf.reduce_sum(tf.matrix_set_diag(cov, tf.zeros(num_neck, tf.float32))), [1])\n",
    "\n",
    "concat_layer = Concatenate(axis=0)([encode_p_neck, encode_g_neck])\n",
    "covLayer = Lambda(CovLayer, name=\"cov\")(concat_layer) # Just a scalar layer\n",
    "\n",
    "# Signed Distance Layer\n",
    "def DisLayer(distance):\n",
    "    return tf.norm(distance, axis=1)\n",
    "\n",
    "distance = Subtract()([encode_p_neck, encode_g_neck])\n",
    "disLayer = Lambda(DisLayer, name=\"dist\")(distance)\n",
    "\n",
    "\n",
    "\n",
    "###### Define 3 loss\n",
    "#loss 1: reconstruction loss for person\n",
    "   ## MSE\n",
    "    \n",
    "#loss 2: reconstruction loss for goods\n",
    "   ## MSE\n",
    "    \n",
    "#loss 3: covariance loss for Covariance Layer\n",
    "def covarianceLoss(CovLayer, zeroCovariance):\n",
    "    return CovLayer - 0\n",
    "\n",
    "#loss 4: distance loss for Distance Layer\n",
    "def distanceLoss(disLayer, label):\n",
    "    sign = 2*label-1\n",
    "    return tf.reduce_mean(tf.maximum(0.0, 0.6*threshold+tf.multiply(sign, disLayer-threshold)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Metric \n",
    "def AUC(distance, label):\n",
    "    output = K.cast(tf.less_equal(distance, threshold), tf.float32)\n",
    "    auc = tf.metrics.auc(output, label)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "losses = {\"recon_p\": 'mse',\n",
    "          \"recon_g\": 'mse',\n",
    "          \"cov\": covarianceLoss,\n",
    "          \"dist\": distanceLoss}\n",
    "\n",
    "weights = {\"recon_p\": 0.25,\n",
    "          \"recon_g\": 0.25,\n",
    "          \"cov\": 0.5,\n",
    "          \"dist\": 0.5}\n",
    "\n",
    "metric = {\"dist\": AUC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected multiples argument to be a vector of length 1 but got length 2\n\t [[{{node training_4/RMSprop/gradients/loss_16/dist_loss/Mean_grad/Tile}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9422d56f7212>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmain_p_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_g_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput_p_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcovLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisLayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXtrain_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mXtrain_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected multiples argument to be a vector of length 1 but got length 2\n\t [[{{node training_4/RMSprop/gradients/loss_16/dist_loss/Mean_grad/Tile}}]]"
     ]
    }
   ],
   "source": [
    "zero_train = np.zeros((Xtrain_p.shape[0],1))\n",
    "zero_val = np.zeros((Xval_p.shape[0],1))\n",
    "\n",
    "model = Model(inputs= [main_p_input, main_g_input, label], outputs = [output_p_out, output_g_out, covLayer, disLayer])\n",
    "model.compile(optimizer='rmsprop', loss=losses, loss_weights=weights, metrics = metric)\n",
    "model.fit([Xtrain_p, Xtrain_g, Ytrain], [Xtrain_p, Xtrain_g, zero_train, Ytrain], validation_data=([Xval_p, Xval_g, Yval], [Xval_p, Xval_g, zero_val, Yval]), epochs=20, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
